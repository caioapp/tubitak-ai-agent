{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd505554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purchase.csv info and head:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28770 entries, 0 to 28769\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   serviceid         28770 non-null  object\n",
      " 1   ownerid           28768 non-null  object\n",
      " 2   ordercreatedtime  28770 non-null  object\n",
      " 3   servicetype       28770 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 899.2+ KB\n",
      "\n",
      "BeforePurchaseDetailsScreen.csv info and head:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 36911 entries, 0 to 36910\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   uuid           15209 non-null  object\n",
      " 1   user_id        15209 non-null  object\n",
      " 2   event_time     15209 non-null  object\n",
      " 3   serviceType    15209 non-null  object\n",
      " 4   uuid.1         21702 non-null  object\n",
      " 5   user_id.1      21702 non-null  object\n",
      " 6   event_time.1   21702 non-null  object\n",
      " 7   serviceType.1  21702 non-null  object\n",
      "dtypes: object(8)\n",
      "memory usage: 2.3+ MB\n",
      "\n",
      "DogAdded.csv info and head:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1707 entries, 0 to 1706\n",
      "Data columns (total 13 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   dogid                 1707 non-null   object \n",
      " 1   ownerid               1707 non-null   object \n",
      " 2   breed                 1707 non-null   object \n",
      " 3   birthday              1707 non-null   object \n",
      " 4   weight                1707 non-null   float64\n",
      " 5   gender                1707 non-null   object \n",
      " 6   isneutered            317 non-null    object \n",
      " 7   havedisabilitiestext  12 non-null     object \n",
      " 8   iseatsfromtheground   317 non-null    object \n",
      " 9   isfightstarter        317 non-null    object \n",
      " 10  istrained             317 non-null    object \n",
      " 11  worryofseparation     164 non-null    object \n",
      " 12  dogaddedtime          1707 non-null   object \n",
      "dtypes: float64(1), object(12)\n",
      "memory usage: 173.5+ KB\n",
      "\n",
      "CatAdded.csv info and head:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 463 entries, 0 to 462\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   catid         463 non-null    object \n",
      " 1   ownerid       463 non-null    object \n",
      " 2   breed         463 non-null    object \n",
      " 3   birthday      463 non-null    object \n",
      " 4   weight        463 non-null    float64\n",
      " 5   gender        463 non-null    object \n",
      " 6   isspayed      463 non-null    bool   \n",
      " 7   cataddedtime  463 non-null    object \n",
      "dtypes: bool(1), float64(1), object(6)\n",
      "memory usage: 25.9+ KB\n",
      "\n",
      "CheckoutPageOpened.csv info and head:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31478 entries, 0 to 31477\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   uuid         31478 non-null  object\n",
      " 1   user_id      31478 non-null  object\n",
      " 2   event_time   31478 non-null  object\n",
      " 3   serviceType  31436 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 983.8+ KB\n",
      "\n",
      "AddressAdded.csv info and head:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1917 entries, 0 to 1916\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   addressid         1917 non-null   object\n",
      " 1   ownerid           1917 non-null   object\n",
      " 2   province          1917 non-null   object\n",
      " 3   district          1917 non-null   object\n",
      " 4   neighborhood      1917 non-null   object\n",
      " 5   addressaddedtime  1917 non-null   object\n",
      "dtypes: object(6)\n",
      "memory usage: 90.0+ KB\n",
      "\n",
      "SignUpCompleted.csv info and head:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10986 entries, 0 to 10985\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   id          10986 non-null  object\n",
      " 1   signuptime  10986 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 171.8+ KB\n",
      "\n",
      "CreditcardAdded.csv info and head:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 725 entries, 0 to 724\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   creditcardid   725 non-null    object\n",
      " 1   ownerid        725 non-null    object\n",
      " 2   cardaddedtime  725 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 17.1+ KB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Path to the folder with the CSV files\n",
    "csv_folder = '../tubitakaiagentprojeleriiinverisetleri/'\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "try:\n",
    "    purchase_df = pd.read_csv(csv_folder+'Purchase.csv')\n",
    "    before_purchase_df = pd.read_csv(csv_folder+'BeforePurchaseDetailsScreen.csv')\n",
    "    dog_added_df = pd.read_csv(csv_folder+'DogAdded.csv')\n",
    "    cat_added_df = pd.read_csv(csv_folder+'CatAdded.csv')\n",
    "    checkout_opened_df = pd.read_csv(csv_folder+'CheckoutPageOpened.csv')\n",
    "    address_added_df = pd.read_csv(csv_folder+'AddressAdded.csv')\n",
    "    sign_up_df = pd.read_csv(csv_folder+'SignUpCompleted.csv')\n",
    "    creditcard_added_df = pd.read_csv(csv_folder+'CreditcardAdded.csv')\n",
    "\n",
    "    # Inspect each dataframe\n",
    "    print(\"Purchase.csv info and head:\")\n",
    "    purchase_df.info()\n",
    "    purchase_df.head()\n",
    "\n",
    "    print(\"\\nBeforePurchaseDetailsScreen.csv info and head:\")\n",
    "    before_purchase_df.info()\n",
    "    before_purchase_df.head()\n",
    "\n",
    "    print(\"\\nDogAdded.csv info and head:\")\n",
    "    dog_added_df.info()\n",
    "    dog_added_df.head()\n",
    "\n",
    "    print(\"\\nCatAdded.csv info and head:\")\n",
    "    cat_added_df.info()\n",
    "    cat_added_df.head()\n",
    "\n",
    "    print(\"\\nCheckoutPageOpened.csv info and head:\")\n",
    "    checkout_opened_df.info()\n",
    "    checkout_opened_df.head()\n",
    "    \n",
    "    print(\"\\nAddressAdded.csv info and head:\")\n",
    "    address_added_df.info()\n",
    "    address_added_df.head()\n",
    "    \n",
    "    print(\"\\nSignUpCompleted.csv info and head:\")\n",
    "    sign_up_df.info()\n",
    "    sign_up_df.head()\n",
    "    \n",
    "    print(\"\\nCreditcardAdded.csv info and head:\")\n",
    "    creditcard_added_df.info()\n",
    "    creditcard_added_df.head()\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading files: {e}. Please ensure all files are uploaded.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e3306f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Possible relations between tables:\n",
      "- AddressAdded <-> CatAdded: common columns: ['ownerid']\n",
      "- AddressAdded <-> CreditcardAdded: common columns: ['ownerid']\n",
      "- AddressAdded <-> DogAdded: common columns: ['ownerid']\n",
      "- AddressAdded <-> Purchase: common columns: ['ownerid']\n",
      "- BeforePurchaseDetailsScreen <-> CheckoutPageOpened: common columns: ['user_id', 'uuid', 'serviceType', 'event_time']\n",
      "- CatAdded <-> AddressAdded: common columns: ['ownerid']\n",
      "- CatAdded <-> CreditcardAdded: common columns: ['ownerid']\n",
      "- CatAdded <-> DogAdded: common columns: ['ownerid', 'gender', 'birthday', 'weight', 'breed']\n",
      "- CatAdded <-> Purchase: common columns: ['ownerid']\n",
      "- CheckoutPageOpened <-> BeforePurchaseDetailsScreen: common columns: ['user_id', 'uuid', 'serviceType', 'event_time']\n",
      "- CreditcardAdded <-> AddressAdded: common columns: ['ownerid']\n",
      "- CreditcardAdded <-> CatAdded: common columns: ['ownerid']\n",
      "- CreditcardAdded <-> DogAdded: common columns: ['ownerid']\n",
      "- CreditcardAdded <-> Purchase: common columns: ['ownerid']\n",
      "- DogAdded <-> AddressAdded: common columns: ['ownerid']\n",
      "- DogAdded <-> CatAdded: common columns: ['ownerid', 'gender', 'birthday', 'weight', 'breed']\n",
      "- DogAdded <-> CreditcardAdded: common columns: ['ownerid']\n",
      "- DogAdded <-> Purchase: common columns: ['ownerid']\n",
      "- Purchase <-> AddressAdded: common columns: ['ownerid']\n",
      "- Purchase <-> CatAdded: common columns: ['ownerid']\n",
      "- Purchase <-> CreditcardAdded: common columns: ['ownerid']\n",
      "- Purchase <-> DogAdded: common columns: ['ownerid']\n"
     ]
    }
   ],
   "source": [
    "# --- Data Cleaning and Preparation ---\n",
    "\n",
    "# 1. Clean BeforePurchaseDetailsScreen.csv\n",
    "# The file has a strange structure with duplicated columns. We need to merge them.\n",
    "before_purchase_part1 = before_purchase_df[['uuid', 'user_id', 'event_time', 'serviceType']].dropna()\n",
    "before_purchase_part2 = before_purchase_df[['uuid.1', 'user_id.1', 'event_time.1', 'serviceType.1']].dropna()\n",
    "before_purchase_part2.columns = ['uuid', 'user_id', 'event_time', 'serviceType']\n",
    "before_purchase_df_cleaned = pd.concat([before_purchase_part1, before_purchase_part2], ignore_index=True)\n",
    "before_purchase_df_cleaned.rename(columns={'user_id': 'ownerid'}, inplace=True)\n",
    "\n",
    "before_purchase_df_cleaned['event_time'] = pd.to_datetime(before_purchase_df_cleaned['event_time'], errors='coerce')\n",
    "\n",
    "# 2. Clean CheckoutPageOpened.csv\n",
    "checkout_opened_df.rename(columns={'user_id': 'ownerid'}, inplace=True)\n",
    "\n",
    "# 3. Clean Purchase.csv\n",
    "purchase_df.dropna(subset=['ownerid'], inplace=True)\n",
    "purchase_df.rename(columns={'servicetype': 'serviceType'}, inplace=True)\n",
    "\n",
    "# 4. Clean and merge DogAdded.csv and CatAdded.csv\n",
    "dog_added_df['pet_type'] = 'dog'\n",
    "dog_added_df.rename(columns={'dogid': 'petid'}, inplace=True)\n",
    "\n",
    "cat_added_df['pet_type'] = 'cat'\n",
    "cat_added_df.rename(columns={'catid': 'petid'}, inplace=True)\n",
    "\n",
    "pets_df = pd.concat([dog_added_df, cat_added_df], ignore_index=True)\n",
    "\n",
    "# 5. Clean AddressAdded.csv\n",
    "address_added_df_cleaned = address_added_df.dropna(subset=['user_id', 'addressid'])\n",
    "address_added_df_cleaned.rename(columns={'user_id': 'ownerid'}, inplace=True)\n",
    "\n",
    "# 6. Clean SignUpCompleted.csv\n",
    "sign_up_df_cleaned = sign_up_df.dropna(subset=['user_id'])\n",
    "sign_up_df_cleaned.rename(columns={'user_id': 'ownerid'}, inplace=True)\n",
    "\n",
    "# 7. Clean CreditcardAdded.csv\n",
    "creditcard_added_df_cleaned = creditcard_added_df.dropna(subset=['user_id', 'creditcardid'])\n",
    "creditcard_added_df_cleaned.rename(columns={'user_id': 'ownerid'}, inplace=True)\n",
    "\n",
    "# --- Merging DataFrames ---\n",
    "\n",
    "# Merge checkout and purchase data to create a conversion funnel\n",
    "# We are considering a conversion if a user who opened the checkout page for a service type made a purchase for the same service type.\n",
    "# To do that, first we will aggregate the checkout and purchase data by ownerid and serviceType\n",
    "checkout_agg = checkout_opened_df.groupby(['ownerid', 'serviceType']).size().reset_index(name='checkout_count')\n",
    "purchase_agg = purchase_df.groupby(['ownerid', 'serviceType']).size().reset_index(name='purchase_count')\n",
    "\n",
    "# Now, we will merge these aggregated dataframes\n",
    "conversion_df = pd.merge(checkout_agg, purchase_agg, on=['ownerid', 'serviceType'], how='left')\n",
    "conversion_df['purchase_count'].fillna(0, inplace=True)\n",
    "conversion_df['converted'] = conversion_df['purchase_count'] > 0\n",
    "\n",
    "# Merge conversion data with pet data\n",
    "merged_df = pd.merge(conversion_df, pets_df, on='ownerid', how='left')\n",
    "\n",
    "# Merge with address, sign up e creditcard info\n",
    "merged_df = pd.merge(merged_df, address_added_df_cleaned, on='ownerid', how='left', suffixes=('', '_address'))\n",
    "merged_df = pd.merge(merged_df, sign_up_df_cleaned, on='ownerid', how='left', suffixes=('', '_signup'))\n",
    "merged_df = pd.merge(merged_df, creditcard_added_df_cleaned, on='ownerid', how='left', suffixes=('', '_creditcard'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99229b8b",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 9.95 GiB for an array with shape (11, 121370913) and data type object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Join all DataFrames with 'user_id' using outer join\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dfs_with_user:\n\u001b[1;32m---> 18\u001b[0m     joined_df \u001b[38;5;241m=\u001b[39m reduce(\u001b[38;5;28;01mlambda\u001b[39;00m left, right: pd\u001b[38;5;241m.\u001b[39mmerge(left, right, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mouter\u001b[39m\u001b[38;5;124m'\u001b[39m, suffixes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_dup\u001b[39m\u001b[38;5;124m'\u001b[39m)), dfs_with_user)\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJoined DataFrame shape:\u001b[39m\u001b[38;5;124m'\u001b[39m, joined_df\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     20\u001b[0m     display(joined_df\u001b[38;5;241m.\u001b[39mhead())\n",
      "Cell \u001b[1;32mIn[4], line 18\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(left, right)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Join all DataFrames with 'user_id' using outer join\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dfs_with_user:\n\u001b[1;32m---> 18\u001b[0m     joined_df \u001b[38;5;241m=\u001b[39m reduce(\u001b[38;5;28;01mlambda\u001b[39;00m left, right: pd\u001b[38;5;241m.\u001b[39mmerge(left, right, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mouter\u001b[39m\u001b[38;5;124m'\u001b[39m, suffixes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_dup\u001b[39m\u001b[38;5;124m'\u001b[39m)), dfs_with_user)\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJoined DataFrame shape:\u001b[39m\u001b[38;5;124m'\u001b[39m, joined_df\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     20\u001b[0m     display(joined_df\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[1;32mc:\\Users\\caioa\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:184\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    170\u001b[0m     op \u001b[38;5;241m=\u001b[39m _MergeOperation(\n\u001b[0;32m    171\u001b[0m         left_df,\n\u001b[0;32m    172\u001b[0m         right_df,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    182\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[0;32m    183\u001b[0m     )\n\u001b[1;32m--> 184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result(copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32mc:\\Users\\caioa\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:888\u001b[0m, in \u001b[0;36m_MergeOperation.get_result\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m    884\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indicator_pre_merge(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright)\n\u001b[0;32m    886\u001b[0m join_index, left_indexer, right_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_join_info()\n\u001b[1;32m--> 888\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_and_concat(\n\u001b[0;32m    889\u001b[0m     join_index, left_indexer, right_indexer, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    890\u001b[0m )\n\u001b[0;32m    891\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_type)\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindicator:\n",
      "File \u001b[1;32mc:\\Users\\caioa\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:848\u001b[0m, in \u001b[0;36m_MergeOperation._reindex_and_concat\u001b[1;34m(self, join_index, left_indexer, right_indexer, copy)\u001b[0m\n\u001b[0;32m    840\u001b[0m llabels, rlabels \u001b[38;5;241m=\u001b[39m _items_overlap_with_suffix(\n\u001b[0;32m    841\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft\u001b[38;5;241m.\u001b[39m_info_axis, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright\u001b[38;5;241m.\u001b[39m_info_axis, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuffixes\n\u001b[0;32m    842\u001b[0m )\n\u001b[0;32m    844\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m left_indexer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_range_indexer(left_indexer, \u001b[38;5;28mlen\u001b[39m(left)):\n\u001b[0;32m    845\u001b[0m     \u001b[38;5;66;03m# Pinning the index here (and in the right code just below) is not\u001b[39;00m\n\u001b[0;32m    846\u001b[0m     \u001b[38;5;66;03m#  necessary, but makes the `.take` more performant if we have e.g.\u001b[39;00m\n\u001b[0;32m    847\u001b[0m     \u001b[38;5;66;03m#  a MultiIndex for left.index.\u001b[39;00m\n\u001b[1;32m--> 848\u001b[0m     lmgr \u001b[38;5;241m=\u001b[39m left\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mreindex_indexer(\n\u001b[0;32m    849\u001b[0m         join_index,\n\u001b[0;32m    850\u001b[0m         left_indexer,\n\u001b[0;32m    851\u001b[0m         axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    852\u001b[0m         copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    853\u001b[0m         only_slice\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    854\u001b[0m         allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    855\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    856\u001b[0m     )\n\u001b[0;32m    857\u001b[0m     left \u001b[38;5;241m=\u001b[39m left\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(lmgr, axes\u001b[38;5;241m=\u001b[39mlmgr\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m    858\u001b[0m left\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m join_index\n",
      "File \u001b[1;32mc:\\Users\\caioa\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:688\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[0;32m    680\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[0;32m    681\u001b[0m         indexer,\n\u001b[0;32m    682\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m    683\u001b[0m         only_slice\u001b[38;5;241m=\u001b[39monly_slice,\n\u001b[0;32m    684\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39muse_na_proxy,\n\u001b[0;32m    685\u001b[0m     )\n\u001b[0;32m    686\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    687\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m--> 688\u001b[0m         blk\u001b[38;5;241m.\u001b[39mtake_nd(\n\u001b[0;32m    689\u001b[0m             indexer,\n\u001b[0;32m    690\u001b[0m             axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    691\u001b[0m             fill_value\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    692\u001b[0m                 fill_value \u001b[38;5;28;01mif\u001b[39;00m fill_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mfill_value\n\u001b[0;32m    693\u001b[0m             ),\n\u001b[0;32m    694\u001b[0m         )\n\u001b[0;32m    695\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[0;32m    696\u001b[0m     ]\n\u001b[0;32m    698\u001b[0m new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m    699\u001b[0m new_axes[axis] \u001b[38;5;241m=\u001b[39m new_axis\n",
      "File \u001b[1;32mc:\\Users\\caioa\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:1307\u001b[0m, in \u001b[0;36mBlock.take_nd\u001b[1;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[0;32m   1304\u001b[0m     allow_fill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;66;03m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001b[39;00m\n\u001b[1;32m-> 1307\u001b[0m new_values \u001b[38;5;241m=\u001b[39m algos\u001b[38;5;241m.\u001b[39mtake_nd(\n\u001b[0;32m   1308\u001b[0m     values, indexer, axis\u001b[38;5;241m=\u001b[39maxis, allow_fill\u001b[38;5;241m=\u001b[39mallow_fill, fill_value\u001b[38;5;241m=\u001b[39mfill_value\n\u001b[0;32m   1309\u001b[0m )\n\u001b[0;32m   1311\u001b[0m \u001b[38;5;66;03m# Called from three places in managers, all of which satisfy\u001b[39;00m\n\u001b[0;32m   1312\u001b[0m \u001b[38;5;66;03m#  these assertions\u001b[39;00m\n\u001b[0;32m   1313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ExtensionBlock):\n\u001b[0;32m   1314\u001b[0m     \u001b[38;5;66;03m# NB: in this case, the 'axis' kwarg will be ignored in the\u001b[39;00m\n\u001b[0;32m   1315\u001b[0m     \u001b[38;5;66;03m#  algos.take_nd call above.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\caioa\\anaconda3\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py:117\u001b[0m, in \u001b[0;36mtake_nd\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mtake(indexer, fill_value\u001b[38;5;241m=\u001b[39mfill_value, allow_fill\u001b[38;5;241m=\u001b[39mallow_fill)\n\u001b[0;32m    116\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(arr)\n\u001b[1;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)\n",
      "File \u001b[1;32mc:\\Users\\caioa\\anaconda3\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py:157\u001b[0m, in \u001b[0;36m_take_nd_ndarray\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    155\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(out_shape, dtype\u001b[38;5;241m=\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 157\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(out_shape, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    159\u001b[0m func \u001b[38;5;241m=\u001b[39m _get_take_nd_function(\n\u001b[0;32m    160\u001b[0m     arr\u001b[38;5;241m.\u001b[39mndim, arr\u001b[38;5;241m.\u001b[39mdtype, out\u001b[38;5;241m.\u001b[39mdtype, axis\u001b[38;5;241m=\u001b[39maxis, mask_info\u001b[38;5;241m=\u001b[39mmask_info\n\u001b[0;32m    161\u001b[0m )\n\u001b[0;32m    162\u001b[0m func(arr, indexer, out, fill_value)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 9.95 GiB for an array with shape (11, 121370913) and data type object"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
