{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05e5c35f",
   "metadata": {},
   "source": [
    "# Next-Purchase Prediction (Ranking) \n",
    "\n",
    "**Purpose.** Predict a user’s **next service** and rank the top candidates at each anchor time *t* (“what will they buy next?”).\n",
    "\n",
    "**This notebook does:**\n",
    "- Builds a **fold-aware ranking dataset** from purchases (UTC).\n",
    "- Trains **LightGBM LambdaRank** on time-based splits.\n",
    "- Evaluates on a hold-out month with **Top-K** metrics (Top-1/Top-2/Hit@3/MRR@3/NDCG@3).\n",
    "- Exports feature importance, per-segment diagnostics, and hold-out predictions.\n",
    "> ℹ️ **Pandas warning:** `infer_datetime_format` is deprecated; the notebook already parses timestamps safely without it. You can remove that argument if you still see a local warning.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af89b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path('/Users/tree/.Trash/tubitakaiagentprojeleriiinverisetleri')             # folder with Purchase.csv\n",
    "PURCHASE_FILE = 'Purchase.csv'   # v3 purchase file\n",
    "TIME_COL = 'ordercreatedtime'    # fallback to 'event_time' if missing\n",
    "USER_ID_CANDS = ['ownerid','user_id','id']\n",
    "SERVICETYPE_CANDS = ['serviceType','servicetype','service_type']\n",
    "\n",
    "# Burst de-dup (lowered as requested)\n",
    "BURST_WINDOW_MINUTES = 30\n",
    "\n",
    "# Horizon classification targets\n",
    "HORIZONS_DAYS = [7, 14, 30]\n",
    "\n",
    "# Negative sampling for ranking\n",
    "N_NEG = 10\n",
    "N_NEG_UNIFORM = 7\n",
    "N_NEG_POP = 3\n",
    "\n",
    "# Recency windows for features (days)\n",
    "RECENCY_WINDOWS = [7, 30, 90]\n",
    "\n",
    "# Recency half-life for Markov prior (days)\n",
    "HALFLIFE_DAYS = 90\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22358e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Imports & helpers ===\n",
    "import pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "def coalesce_id(df, candidates):\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return df[c]\n",
    "    return pd.Series([np.nan]*len(df))\n",
    "\n",
    "def parse_time_utc(s, local_tz='Europe/Istanbul'):\n",
    "    ts = pd.to_datetime(s, errors='coerce', utc=True, infer_datetime_format=True)\n",
    "    if getattr(ts.dt, 'tz', None) is None:\n",
    "        ts = pd.to_datetime(s, errors='coerce')\n",
    "        ts = ts.dt.tz_localize(local_tz, ambiguous='NaT', nonexistent='NaT').dt.tz_convert('UTC')\n",
    "    return ts\n",
    "\n",
    "def norm_service(series: pd.Series) -> pd.Series:\n",
    "    out = series.astype(str).str.strip().str.lower()\n",
    "    out = out.replace({'nan': np.nan, 'none': np.nan, 'nat': np.nan, '': np.nan,\n",
    "                       'walk & care': 'walkandcare', 'walk_and_care': 'walkandcare'})\n",
    "    return out\n",
    "\n",
    "def dedup_bursts(df, window_min=30):\n",
    "    df = df.copy()\n",
    "    gap = (df['purchase_time'] - df.groupby('user_id')['purchase_time'].shift(1)).dt.total_seconds()/60.0\n",
    "    new_burst = (gap.isna()) | (gap > window_min)\n",
    "    burst_id = new_burst.groupby(df['user_id']).cumsum()\n",
    "    first = df.groupby(['user_id', burst_id], as_index=False).first()\n",
    "    first = first.rename(columns={'purchase_time':'purchase_time'})\n",
    "    first['burst_size'] = df.groupby(['user_id', burst_id]).size().values\n",
    "    for col in ['amount','total','price']:\n",
    "        if col in df.columns:\n",
    "            first[col] = df.groupby(['user_id', burst_id])[col].sum().values\n",
    "    return first.reset_index(drop=True)\n",
    "\n",
    "def recency_weight(age_days, halflife_days):\n",
    "    return np.power(0.5, np.clip(age_days, 0, None) / max(halflife_days, 1e-9))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb4ea0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows after dedup: 12810 | Users: 1614 | Time: 2024-12-24 21:41:02.022000+00:00 → 2025-08-04 09:34:52.801000+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_y/5xqwn5xx5_s9dsm9q1ymghdr0000gn/T/ipykernel_13190/2872185038.py:13: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  ts = pd.to_datetime(s, errors='coerce', utc=True, infer_datetime_format=True)\n"
     ]
    }
   ],
   "source": [
    "# === Load & normalize purchases ===\n",
    "p = pd.read_csv(DATA_DIR / PURCHASE_FILE)\n",
    "\n",
    "p['user_id'] = coalesce_id(p, USER_ID_CANDS).astype(str).replace({'nan': np.nan})\n",
    "if TIME_COL not in p.columns:\n",
    "    alt = 'event_time' if 'event_time' in p.columns else None\n",
    "    if not alt: raise KeyError(f\"Time col '{TIME_COL}' not found and no 'event_time' fallback present.\")\n",
    "    p['purchase_time'] = parse_time_utc(p[alt])\n",
    "else:\n",
    "    p['purchase_time'] = parse_time_utc(p[TIME_COL])\n",
    "\n",
    "st_col = None\n",
    "for c in SERVICETYPE_CANDS:\n",
    "    if c in p.columns:\n",
    "        st_col = c; break\n",
    "p['serviceType'] = norm_service(p[st_col]) if st_col else np.nan\n",
    "\n",
    "CTX_COLS = [c for c in ['petType','platform','city','discount','promo','amount','total','price'] if c in p.columns]\n",
    "\n",
    "p = p.dropna(subset=['user_id','purchase_time']).copy()\n",
    "p['user_id'] = p['user_id'].astype(str)\n",
    "\n",
    "p = p.sort_values(['user_id','purchase_time']).reset_index(drop=True)\n",
    "p = dedup_bursts(p, window_min=BURST_WINDOW_MINUTES)\n",
    "\n",
    "print('Rows after dedup:', len(p), '| Users:', p['user_id'].nunique(),\n",
    "      '| Time:', p['purchase_time'].min(), '→', p['purchase_time'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b21b155c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'train_end': Timestamp('2025-06-01 00:00:00+0000', tz='UTC'),\n",
       "   'val_start': Timestamp('2025-06-01 00:00:00+0000', tz='UTC'),\n",
       "   'val_end': Timestamp('2025-07-01 00:00:00+0000', tz='UTC')},\n",
       "  {'train_end': Timestamp('2025-07-01 00:00:00+0000', tz='UTC'),\n",
       "   'val_start': Timestamp('2025-07-01 00:00:00+0000', tz='UTC'),\n",
       "   'val_end': Timestamp('2025-08-01 00:00:00+0000', tz='UTC')}],\n",
       " {'train_end': Timestamp('2025-08-01 00:00:00+0000', tz='UTC'),\n",
       "  'test_start': Timestamp('2025-08-01 00:00:00+0000', tz='UTC'),\n",
       "  'test_end': Timestamp('2025-09-01 00:00:00+0000', tz='UTC')})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Build rolling time folds ===\n",
    "max_ts = p['purchase_time'].max()\n",
    "anchor = pd.Timestamp(year=max_ts.year, month=max_ts.month, day=1, tz='UTC') + pd.offsets.MonthBegin(1)\n",
    "month_starts = [(anchor - pd.offsets.MonthBegin(k)).tz_convert('UTC') for k in range(4,0,-1)]\n",
    "\n",
    "folds = []\n",
    "if len(month_starts) >= 3:\n",
    "    folds.append({'train_end': month_starts[1], 'val_start': month_starts[1], 'val_end': month_starts[2]})\n",
    "    folds.append({'train_end': month_starts[2], 'val_start': month_starts[2], 'val_end': month_starts[3]})\n",
    "holdout = {'train_end': month_starts[3], 'test_start': month_starts[3], 'test_end': anchor}\n",
    "\n",
    "folds, holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e97d72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Utilities ===\n",
    "def slice_time(df, start=None, end=None):\n",
    "    m = df\n",
    "    if start is not None:\n",
    "        m = m[m['purchase_time'] >= start]\n",
    "    if end is not None:\n",
    "        m = m[m['purchase_time'] < end]\n",
    "    return m.copy()\n",
    "\n",
    "from collections import defaultdict\n",
    "def build_markov_prior(train_df, halflife_days=90):\n",
    "    d = train_df.copy()\n",
    "    d['next_service'] = d.groupby('user_id')['serviceType'].shift(-1)\n",
    "    d['this_time'] = d['purchase_time']\n",
    "    d['next_time'] = d.groupby('user_id')['purchase_time'].shift(-1)\n",
    "    d = d.dropna(subset=['serviceType','next_service','this_time','next_time'])\n",
    "    train_max = d['this_time'].max()\n",
    "    d['age_days'] = (train_max - d['this_time']).dt.total_seconds()/(24*3600)\n",
    "    d['w'] = recency_weight(d['age_days'], halflife_days)\n",
    "    rw = d.groupby(['serviceType','next_service'])['w'].sum().rename('w_count').reset_index()\n",
    "    tot = rw.groupby('serviceType')['w_count'].transform('sum')\n",
    "    rw['prob'] = np.where(tot>0, rw['w_count']/tot, np.nan)\n",
    "    prior = defaultdict(dict)\n",
    "    for _, r in rw.iterrows():\n",
    "        prior[r['serviceType']][r['next_service']] = r['prob']\n",
    "    return prior, rw\n",
    "\n",
    "def service_popularity(train_df):\n",
    "    return train_df['serviceType'].value_counts(normalize=True).to_dict(), train_df['serviceType'].value_counts().to_dict()\n",
    "\n",
    "def build_feature_row(user_hist, t, candidate, current, ctx_row=None, windows=[7,30,90]):\n",
    "    feats = {}\n",
    "    if not user_hist.empty:\n",
    "        last_time = user_hist['purchase_time'].max()\n",
    "        feats['recency_days'] = (t - last_time).total_seconds()/(24*3600)\n",
    "    else:\n",
    "        feats['recency_days'] = np.nan\n",
    "    for w in windows:\n",
    "        feats[f'cnt_{w}d'] = (user_hist['purchase_time'] >= (t - pd.Timedelta(days=w))).sum()\n",
    "    uh_cand = user_hist[user_hist['serviceType']==candidate]\n",
    "    feats['cand_has_hist'] = int(len(uh_cand) > 0)\n",
    "    feats['cand_recency_days'] = (t - uh_cand['purchase_time'].max()).total_seconds()/(24*3600) if len(uh_cand) else np.nan\n",
    "    for w in windows:\n",
    "        feats[f'cand_cnt_{w}d'] = (uh_cand['purchase_time'] >= (t - pd.Timedelta(days=w))).sum()\n",
    "    feats['last_service'] = user_hist.sort_values('purchase_time').iloc[-1]['serviceType'] if not user_hist.empty else np.nan\n",
    "    local = t.tz_convert('Europe/Istanbul')\n",
    "    feats['dow'] = local.dayofweek; feats['hour'] = local.hour\n",
    "    if ctx_row is not None:\n",
    "        for c in ctx_row.index:\n",
    "            feats[f'ctx_{c}'] = ctx_row[c]\n",
    "    return feats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8004d2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Dataset constructors ===\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "def sample_negatives(all_services, positive, pop_probs, n_total=10, n_uniform=7, n_pop=3):\n",
    "    pool = [s for s in all_services if s != positive]\n",
    "    uni = rng.choice(pool, size=min(n_uniform, len(pool)), replace=False) if len(pool) else []\n",
    "    if n_pop and len(pool):\n",
    "        weights = np.array([pop_probs.get(s, 0.0) for s in pool], dtype=float)\n",
    "        if weights.sum() == 0:\n",
    "            pop = []\n",
    "        else:\n",
    "            weights = weights/weights.sum()\n",
    "            pop = rng.choice(pool, size=min(n_pop, len(pool)), replace=False, p=weights)\n",
    "    else:\n",
    "        pop = []\n",
    "    cands = list(dict.fromkeys(list(uni) + list(pop)))\n",
    "    while len(cands) < n_total and len(cands) < len(pool):\n",
    "        add = rng.choice([s for s in pool if s not in cands])\n",
    "        cands.append(add)\n",
    "    return cands\n",
    "\n",
    "def build_ranking_dataset(train_df, val_df, markov_prior, all_services, pop_probs):\n",
    "    rows = []\n",
    "    by_user_train = {u: df.sort_values('purchase_time') for u, df in train_df.groupby('user_id')}\n",
    "    # Build user sequences from combined train+val to get the \"true next\" in val period\n",
    "    by_user_val = {u: df.sort_values('purchase_time') for u, df in val_df.groupby('user_id')}\n",
    "    for u, vdf in by_user_val.items():\n",
    "        tdf = by_user_train.get(u, pd.DataFrame(columns=train_df.columns))\n",
    "        for idx, row in vdf.iterrows():\n",
    "            t = row['purchase_time']; cur = row['serviceType']\n",
    "            # user history strictly before t from TRAIN\n",
    "            hist = tdf[tdf['purchase_time'] < t]\n",
    "            # next in VAL for this user\n",
    "            future = vdf[vdf['purchase_time'] > t]\n",
    "            if future.empty: \n",
    "                continue\n",
    "            y_pos = future.iloc[0]['serviceType']\n",
    "            ctx_cols = [c for c in ['petType','platform','city','discount','promo'] if c in vdf.columns]\n",
    "            ctx_vals = row[ctx_cols] if ctx_cols else None\n",
    "            feats_pos = build_feature_row(hist, t, y_pos, cur, ctx_vals)\n",
    "            feats_pos['markov_prior'] = markov_prior.get(cur, {}).get(y_pos, np.nan)\n",
    "            rows.append({'user_id': u, 'time': t, 'current': cur, 'candidate': y_pos, 'label': 1, **feats_pos})\n",
    "            negs = sample_negatives(all_services, y_pos, pop_probs)\n",
    "            for neg in negs:\n",
    "                feats_neg = build_feature_row(hist, t, neg, cur, ctx_vals)\n",
    "                feats_neg['markov_prior'] = markov_prior.get(cur, {}).get(neg, np.nan)\n",
    "                rows.append({'user_id': u, 'time': t, 'current': cur, 'candidate': neg, 'label': 0, **feats_neg})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def build_horizon_dataset(train_df, val_df, all_services, horizons=[7,14,30]):\n",
    "    rows = []\n",
    "    by_user = {u: df.sort_values('purchase_time') for u, df in pd.concat([train_df, val_df]).groupby('user_id')}\n",
    "    for u, vdf in val_df.groupby('user_id'):\n",
    "        user_all = by_user.get(u, pd.DataFrame(columns=train_df.columns))\n",
    "        vdf = vdf.sort_values('purchase_time')\n",
    "        for _, row in vdf.iterrows():\n",
    "            t = row['purchase_time']; cur = row['serviceType']\n",
    "            hist = user_all[user_all['purchase_time'] < t]\n",
    "            future = user_all[user_all['purchase_time'] > t][['serviceType', 'purchase_time']]\n",
    "            future_first = future.groupby('serviceType', as_index=True)['purchase_time'].min()\n",
    "            ctx_cols = [c for c in ['petType','platform','city','discount','promo'] if c in vdf.columns]\n",
    "            ctx_vals = row[ctx_cols] if ctx_cols else None\n",
    "            for cand in all_services:\n",
    "                feats = build_feature_row(hist, t, cand, cur, ctx_vals)\n",
    "                ft = future_first.get(cand, pd.NaT)\n",
    "                for T in horizons:\n",
    "                    cutoff = t + pd.Timedelta(days=int(T))\n",
    "                    label = int(pd.notna(ft) and (ft <= cutoff))\n",
    "                    rows.append({\n",
    "                        'user_id': u,\n",
    "                        'time': t,\n",
    "                        'current': cur,\n",
    "                        'candidate': cand,\n",
    "                        'T_days': T,\n",
    "                        'label': label,\n",
    "                    })\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfc8c5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: rank_rows=32,360 | horiz_rows=126,330 | services=10\n",
      "Fold 2: rank_rows=29,050 | horiz_rows=113,070 | services=10\n",
      "Holdout: 1450 ranking rows | 11310 horizon rows\n",
      "Saved to /Users/tree/Projects/tubitak-ai-agent/notebooks/datasets_v4\n"
     ]
    }
   ],
   "source": [
    "# === Execute folds and write CSVs ===\n",
    "from pathlib import Path\n",
    "OUT_DIR = Path('datasets_v4'); OUT_DIR.mkdir(exist_ok=True)\n",
    "all_services = sorted(p['serviceType'].dropna().unique().tolist())\n",
    "\n",
    "for i, f in enumerate(folds, start=1):\n",
    "    train = slice_time(p, end=f['train_end'])\n",
    "    val   = slice_time(p, start=f['val_start'], end=f['val_end'])\n",
    "    markov_prior, rw = build_markov_prior(train, halflife_days=HALFLIFE_DAYS)\n",
    "    pop_probs, pop_counts = service_popularity(train)\n",
    "    rank_df = build_ranking_dataset(train, val, markov_prior, all_services, pop_probs)\n",
    "    horiz_df = build_horizon_dataset(train, val, all_services, horizons=HORIZONS_DAYS)\n",
    "    rank_df.to_csv(OUT_DIR / f'fold{i}_ranking.csv', index=False)\n",
    "    horiz_df.to_csv(OUT_DIR / f'fold{i}_horizon.csv', index=False)\n",
    "    rw.to_csv(OUT_DIR / f'fold{i}_markov_prior.csv', index=False)\n",
    "    print(f'Fold {i}: rank_rows={len(rank_df):,} | horiz_rows={len(horiz_df):,} | services={len(all_services)}')\n",
    "\n",
    "# Holdout\n",
    "train_all = slice_time(p, end=holdout['train_end'])\n",
    "test      = slice_time(p, start=holdout['test_start'], end=holdout['test_end'])\n",
    "markov_prior_H, rw_H = build_markov_prior(train_all, halflife_days=HALFLIFE_DAYS)\n",
    "pop_probs_H, _ = service_popularity(train_all)\n",
    "rank_test  = build_ranking_dataset(train_all, test, markov_prior_H, all_services, pop_probs_H)\n",
    "horiz_test = build_horizon_dataset(train_all, test, all_services, horizons=HORIZONS_DAYS)\n",
    "rank_test.to_csv(OUT_DIR / 'holdout_ranking.csv', index=False)\n",
    "horiz_test.to_csv(OUT_DIR / 'holdout_horizon.csv', index=False)\n",
    "rw_H.to_csv(OUT_DIR / 'holdout_markov_prior.csv', index=False)\n",
    "print('Holdout:', len(rank_test), 'ranking rows |', len(horiz_test), 'horizon rows')\n",
    "print('Saved to', OUT_DIR.resolve())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1d66a7",
   "metadata": {},
   "source": [
    "## Optional: Shift holdout if the last month is incomplete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19ddcea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout rows (current): 3769\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# If the holdout period has very few events (e.g., partial month), shift anchor back by one month.\n",
    "MIN_TEST_ROWS = 350  #adjustable\n",
    "test_rows = len(slice_time(p, start=holdout['test_start'], end=holdout['test_end']))\n",
    "print('Holdout rows (current):', test_rows)\n",
    "if test_rows < MIN_TEST_ROWS:\n",
    "    print('Holdout too small; shifting anchor back by one month.')\n",
    "    new_anchor = anchor - pd.offsets.MonthBegin(1)\n",
    "    month_starts = [(new_anchor - pd.offsets.MonthBegin(k)).tz_convert('UTC') for k in range(4,0,-1)]\n",
    "    folds = []\n",
    "    if len(month_starts) >= 3:\n",
    "        folds.append({'train_end': month_starts[1], 'val_start': month_starts[1], 'val_end': month_starts[2]})\n",
    "        folds.append({'train_end': month_starts[2], 'val_start': month_starts[2], 'val_end': month_starts[3]})\n",
    "    holdout = {'train_end': month_starts[3], 'test_start': month_starts[3], 'test_end': new_anchor}\n",
    "    print('Shifted folds and holdout to ensure a fuller test month.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0b032f",
   "metadata": {},
   "source": [
    "\n",
    "# Training — A) Next-service Ranking (LightGBM / XGBoost)\n",
    "This section trains a **pairwise ranking model** on the datasets built above.\n",
    "\n",
    "**Features included:** recency windows, candidate-specific counts/recency, last service, seasonality, Markov prior, plus any available context columns (petType/platform/city/discount/promo).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9cf6ad4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "DATASETS = Path(\"datasets_v4\")\n",
    "RANK_FILES = [\"fold1_ranking.csv\", \"fold2_ranking.csv\"]\n",
    "HOLDOUT_RANK = \"holdout_ranking.csv\"\n",
    "# Utility to load a ranking csv\n",
    "\n",
    "def load_rank_df(name: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(DATASETS / name, parse_dates=[\"time\"])  # time parsed for anchor_id\n",
    "    # build anchor_id (1 anchor = one query context) if missing\n",
    "    if \"anchor_id\" not in df.columns:\n",
    "        df[\"anchor_id\"] = df[\"user_id\"].astype(str) + \"|\" + df[\"time\"].astype(\"int64\").astype(str)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4b3d472a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows: 61410 | Holdout rows: 1450\n",
      "Train anchors: 6141 | Holdout anchors: 145\n",
      "Categorical: ['current', 'candidate', 'last_service']\n",
      "Numeric: ['recency_days', 'cnt_7d', 'cnt_30d', 'cnt_90d', 'cand_has_hist', 'cand_recency_days', 'cand_cnt_7d', 'cand_cnt_30d', 'cand_cnt_90d', 'dow', 'hour', 'markov_prior']\n"
     ]
    }
   ],
   "source": [
    "# Load training folds (concat) and holdout\n",
    "train_raw = pd.concat([load_rank_df(f) for f in RANK_FILES if (DATASETS / f).exists()], ignore_index=True)\n",
    "test_raw  = load_rank_df(HOLDOUT_RANK)\n",
    "\n",
    "print(\"Train rows:\", len(train_raw), \"| Holdout rows:\", len(test_raw))\n",
    "print(\"Train anchors:\", train_raw[\"anchor_id\"].nunique(), \"| Holdout anchors:\", test_raw[\"anchor_id\"].nunique())\n",
    "\n",
    "# Identify features\n",
    "cat_cols = [c for c in [\"current\", \"candidate\", \"last_service\"] if c in train_raw.columns]\n",
    "ctx_cols = [c for c in train_raw.columns if c.startswith(\"ctx_\")]\n",
    "exclude = set([\"user_id\", \"time\", \"anchor_id\", \"label\"]) | set(cat_cols) | set(ctx_cols)\n",
    "num_cols = [c for c in train_raw.columns if c not in exclude]\n",
    "print(\"Categorical:\", cat_cols + ctx_cols)\n",
    "print(\"Numeric:\", num_cols)\n",
    "\n",
    "# Keep copies for baselines before encoding\n",
    "train_text = train_raw[[\"anchor_id\", \"candidate\"]].copy()\n",
    "\n",
    "# Fit a single OrdinalEncoder on (cat + ctx) over TRAIN, then transform TRAIN and TEST\n",
    "enc = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
    "if cat_cols + ctx_cols:\n",
    "    train_enc = train_raw.copy()\n",
    "    test_enc  = test_raw.copy()\n",
    "\n",
    "    train_enc[cat_cols + ctx_cols] = enc.fit_transform(train_enc[cat_cols + ctx_cols].astype(str))\n",
    "    test_enc[cat_cols + ctx_cols]  = enc.transform(test_enc[cat_cols + ctx_cols].astype(str))\n",
    "else:\n",
    "    train_enc, test_enc = train_raw.copy(), test_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "92a2f577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shapes: (61410, 19) 6141 | Test shapes: (1450, 19) 145\n"
     ]
    }
   ],
   "source": [
    "# Feature engineering — log1p counts + ratios vs 90d\n",
    "for base in ['cnt','cand_cnt']:\n",
    "    for win in [7, 30, 90]:\n",
    "        col = f'{base}_{win}d'\n",
    "        if col in train_enc.columns:\n",
    "            train_enc[col] = np.log1p(train_enc[col])\n",
    "        if col in test_enc.columns:\n",
    "            test_enc[col] = np.log1p(test_enc[col])\n",
    "\n",
    "# Short/long ratios (guard for missing columns)\n",
    "new_feats = []\n",
    "for base in ['cnt','cand_cnt']:\n",
    "    if all(f'{base}_{w}d' in train_enc.columns for w in [7,90]):\n",
    "        train_enc[f'{base}_r_7_90'] = (train_enc[f'{base}_7d']+1)/(train_enc[f'{base}_90d']+1)\n",
    "        test_enc[f'{base}_r_7_90']  = (test_enc[f'{base}_7d']+1)/(test_enc[f'{base}_90d']+1)\n",
    "        new_feats.append(f'{base}_r_7_90')\n",
    "    if all(f'{base}_{w}d' in train_enc.columns for w in [30,90]):\n",
    "        train_enc[f'{base}_r_30_90'] = (train_enc[f'{base}_30d']+1)/(train_enc[f'{base}_90d']+1)\n",
    "        test_enc[f'{base}_r_30_90']  = (test_enc[f'{base}_30d']+1)/(test_enc[f'{base}_90d']+1)\n",
    "        new_feats.append(f'{base}_r_30_90')\n",
    "\n",
    "for f in new_feats:\n",
    "    if f not in num_cols:\n",
    "        num_cols.append(f)\n",
    "\n",
    "# Prepare arrays for LightGBM LambdaRank\n",
    "X_train = train_enc[cat_cols + ctx_cols + num_cols].astype(float).fillna(-1.0).values\n",
    "y_train = train_enc[\"label\"].astype(int).values\n",
    "groups_train = train_enc.groupby(\"anchor_id\").size().values\n",
    "\n",
    "X_test = test_enc[cat_cols + ctx_cols + num_cols].astype(float).fillna(-1.0).values\n",
    "y_test = test_enc[\"label\"].astype(int).values\n",
    "groups_test = test_enc.groupby(\"anchor_id\").size().values\n",
    "\n",
    "print(\"Train shapes:\", X_train.shape, len(groups_train), \"| Test shapes:\", X_test.shape, len(groups_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b0c1507e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics helpers\n",
    "def group_metrics(df: pd.DataFrame, score_col: str = \"score\") -> dict:\n",
    "    top1 = []; top2 = []; hit3 = []; mrr3 = []; ndcg3 = []\n",
    "    for _, g in df.groupby(\"anchor_id\"):\n",
    "        g = g.sort_values(score_col, ascending=False)\n",
    "        y = g[\"label\"].values\n",
    "        top1.append(1.0 if y[0] == 1 else 0.0)\n",
    "        top2.append(1.0 if y[:2].sum() > 0 else 0.0)\n",
    "        hit3.append(1.0 if y[:3].sum() > 0 else 0.0)\n",
    "        if 1 in y[:3]:\n",
    "            r = np.argmax(y[:3] == 1) + 1\n",
    "            mrr3.append(1.0 / r)\n",
    "        else:\n",
    "            mrr3.append(0.0)\n",
    "        ndcg3.append(ndcg_score([y[:3]], [g[score_col].values[:3]]))\n",
    "    return {\n",
    "        \"top1\": float(np.mean(top1)),\n",
    "        \"top2\": float(np.mean(top2)),\n",
    "        \"hit3\": float(np.mean(hit3)),\n",
    "        \"mrr3\": float(np.mean(mrr3)),\n",
    "        \"ndcg3\": float(np.mean(ndcg3)),\n",
    "        \"anchors\": int(df[\"anchor_id\"].nunique()),\n",
    "    }\n",
    "\n",
    "def ndcg_full(df: pd.DataFrame, score_col: str = \"score\") -> float:\n",
    "    vals = []\n",
    "    for _, g in df.groupby(\"anchor_id\"):\n",
    "        vals.append(ndcg_score([g[\"label\"].values], [g[score_col].values]))\n",
    "    return float(np.mean(vals))\n",
    "\n",
    "# generic predictor attach (avoids duplicate 'score')\n",
    "\n",
    "def with_score(df: pd.DataFrame, model, X, col: str = \"score\") -> pd.DataFrame:\n",
    "    df2 = df.copy()\n",
    "    if \"anchor_id\" not in df2.columns:\n",
    "        df2[\"anchor_id\"] = df2[\"user_id\"].astype(str) + \"|\" + df2[\"time\"].astype(\"int64\").astype(str)\n",
    "    df2 = df2.loc[:, ~df2.columns.duplicated()]\n",
    "    for c in list(df2.columns[df2.columns == col]):\n",
    "        df2 = df2.drop(columns=c)\n",
    "    num_iter = getattr(model, \"best_iteration\", None)\n",
    "    df2[col] = model.predict(X, num_iteration=num_iter)\n",
    "    return df2\n",
    "\n",
    "# decode helper for encoded columns\n",
    "\n",
    "def inverse_col_from_encoder(series_num: pd.Series, col_name: str, enc: OrdinalEncoder, cols: list) -> pd.Series:\n",
    "    if col_name not in cols:\n",
    "        return series_num\n",
    "    idx = cols.index(col_name)\n",
    "    cats = list(enc.categories_[idx])\n",
    "    s = pd.to_numeric(series_num, errors=\"coerce\").where(lambda x: x >= 0, np.nan).round().astype(\"Int64\")\n",
    "    return s.map(lambda i: cats[int(i)] if pd.notna(i) and int(i) < len(cats) else np.nan).astype(\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e95ec6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid's ndcg@1: 0.737931\tvalid's ndcg@3: 0.900569\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid's ndcg@1: 0.751724\tvalid's ndcg@3: 0.90566\n",
      "{'top1': 0.751724, 'top2': 0.97931, 'hit3': 1.0, 'mrr3': 0.872414, 'ndcg3': 0.90566, 'anchors': 145, 'ndcg_full': 0.90566}\n"
     ]
    }
   ],
   "source": [
    "# LightGBM LambdaRank\n",
    "import lightgbm as lgb\n",
    "\n",
    "params = dict(\n",
    "    objective=\"lambdarank\",\n",
    "    metric=\"ndcg\",\n",
    "    ndcg_eval_at=[1, 3],\n",
    "    learning_rate=0.03,\n",
    "    num_leaves=31,\n",
    "    min_data_in_leaf=20,\n",
    "    feature_fraction=0.9,\n",
    "    bagging_fraction=0.9,\n",
    "    bagging_freq=1,\n",
    "    max_depth=-1,\n",
    "    verbose=-1,\n",
    ")\n",
    "\n",
    "train_set = lgb.Dataset(X_train, label=y_train, group=groups_train, free_raw_data=False)\n",
    "valid_set = lgb.Dataset(X_test, label=y_test, group=groups_test, reference=train_set, free_raw_data=False)\n",
    "\n",
    "print(\"Training until validation scores don't improve for 50 rounds\")\n",
    "model_lgb = lgb.train(\n",
    "    params,\n",
    "    train_set,\n",
    "    num_boost_round=1000,\n",
    "    valid_sets=[valid_set],\n",
    "    valid_names=[\"valid\"],\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=50), lgb.log_evaluation(period=50)],\n",
    ")\n",
    "# Attach predictions on holdout and compute metrics\n",
    "hold_lgb = with_score(test_enc, model_lgb, X_test, col=\"score\")\n",
    "metrics_lgb = group_metrics(hold_lgb, \"score\"); metrics_lgb[\"ndcg_full\"] = ndcg_full(hold_lgb, \"score\")\n",
    "print({k: round(v, 6) if isinstance(v, float) else v for k, v in metrics_lgb.items()})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "899f1cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Popularity ties: 0/145 anchors (0.0%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top1</th>\n",
       "      <th>top2</th>\n",
       "      <th>hit3</th>\n",
       "      <th>mrr3</th>\n",
       "      <th>ndcg3</th>\n",
       "      <th>anchors</th>\n",
       "      <th>ndcg_full</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.7517</td>\n",
       "      <td>0.9793</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8724</td>\n",
       "      <td>0.9057</td>\n",
       "      <td>145</td>\n",
       "      <td>0.9057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Markov-only</th>\n",
       "      <td>0.7310</td>\n",
       "      <td>0.9793</td>\n",
       "      <td>0.9931</td>\n",
       "      <td>0.8598</td>\n",
       "      <td>0.8946</td>\n",
       "      <td>145</td>\n",
       "      <td>0.8972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Popularity-only</th>\n",
       "      <td>0.6690</td>\n",
       "      <td>0.9655</td>\n",
       "      <td>0.9724</td>\n",
       "      <td>0.8195</td>\n",
       "      <td>0.8595</td>\n",
       "      <td>145</td>\n",
       "      <td>0.8701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   top1    top2    hit3    mrr3   ndcg3  anchors  ndcg_full\n",
       "model                                                                      \n",
       "LightGBM         0.7517  0.9793  1.0000  0.8724  0.9057      145     0.9057\n",
       "Markov-only      0.7310  0.9793  0.9931  0.8598  0.8946      145     0.8972\n",
       "Popularity-only  0.6690  0.9655  0.9724  0.8195  0.8595      145     0.8701"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Baselines: Markov-only and Popularity-only\n",
    "#Uses decoded candidate/current names to avoid numeric-vs-text mismatches.\n",
    "cols_for_encoder = cat_cols + ctx_cols\n",
    "base_df = hold_lgb.copy()\n",
    "\n",
    "# decode candidate/current if they were encoded\n",
    "if \"candidate\" in base_df.columns and \"candidate\" in cat_cols:\n",
    "    base_df[\"candidate_text\"] = inverse_col_from_encoder(base_df[\"candidate\"], \"candidate\", enc, cols_for_encoder)\n",
    "if \"current\" in base_df.columns and \"current\" in cat_cols:\n",
    "    base_df[\"current_text\"] = inverse_col_from_encoder(base_df[\"current\"], \"current\", enc, cols_for_encoder)\n",
    "\n",
    "# Markov-only baseline: prefer markov_prior already in holdout csv\n",
    "mkv_df = base_df.copy()\n",
    "if \"markov_prior\" not in mkv_df.columns:\n",
    "    # Merge from raw holdout file if not present (joins on anchor_id + textual candidate)\n",
    "    raw_hold = load_rank_df(HOLDOUT_RANK)  # raw has textual candidate\n",
    "    mkv_df = mkv_df.merge(\n",
    "        raw_hold[[\"anchor_id\", \"candidate\", \"markov_prior\"]],\n",
    "        left_on=[\"anchor_id\", \"candidate_text\"],\n",
    "        right_on=[\"anchor_id\", \"candidate\"],\n",
    "        how=\"left\",\n",
    "    )\n",
    "\n",
    "mkv_df[\"score_mkv\"] = mkv_df[\"markov_prior\"].fillna(0.0)\n",
    "metrics_mkv = group_metrics(mkv_df, \"score_mkv\"); metrics_mkv[\"ndcg_full\"] = ndcg_full(mkv_df, \"score_mkv\")\n",
    "\n",
    "# Popularity-only baseline\n",
    "try:\n",
    "    pop_map = pop_probs_H  # dict[str -> prob]\n",
    "except Exception:\n",
    "    pop_map = train_raw[\"candidate\"].value_counts(normalize=True).to_dict()\n",
    "\n",
    "pop_df = base_df.copy()\n",
    "cand_key = \"candidate_text\" if \"candidate_text\" in pop_df.columns else \"candidate\"\n",
    "pop_df[\"score_pop\"] = pop_df[cand_key].map(pop_map).fillna(0.0)\n",
    "\n",
    "# Tie rate on popularity (ties make Top-1 unstable)\n",
    "ties = sum(g[\"score_pop\"].nunique() <= 1 for _, g in pop_df.groupby(\"anchor_id\"))\n",
    "print(f\"Popularity ties: {ties}/{pop_df['anchor_id'].nunique()} anchors ({ties / max(pop_df['anchor_id'].nunique(),1):.1%})\")\n",
    "\n",
    "metrics_pop = group_metrics(pop_df, \"score_pop\"); metrics_pop[\"ndcg_full\"] = ndcg_full(pop_df, \"score_pop\")\n",
    "\n",
    "baseline_table = pd.DataFrame([\n",
    "    {\"model\": \"LightGBM\", **metrics_lgb},\n",
    "    {\"model\": \"Markov-only\", **metrics_mkv},\n",
    "    {\"model\": \"Popularity-only\", **metrics_pop},\n",
    "]).set_index(\"model\").round(4)\n",
    "display(baseline_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5bb3e497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "McNemar exact p-value: 0.6291 | wins: 10 | loss: 7 | discordant: 17\n"
     ]
    }
   ],
   "source": [
    "import math, numpy as np, pandas as pd\n",
    "\n",
    "# Ensure lgb_df (LightGBM predictions) exists\n",
    "try:\n",
    "    _ = lgb_df.shape\n",
    "except NameError:\n",
    "    if 'hold_lgb' in globals():\n",
    "        lgb_df = hold_lgb.copy()\n",
    "    else:\n",
    "        lgb_df = with_score(test_enc, model_lgb, X_test, col='score')\n",
    "    lgb_df = lgb_df.loc[:, ~lgb_df.columns.duplicated()]\n",
    "    if 'anchor_id' not in lgb_df.columns:\n",
    "        lgb_df['anchor_id'] = lgb_df['user_id'].astype(str) + '|' + lgb_df['time'].astype('int64').astype(str)\n",
    "\n",
    "# Ensure mkv_df (Markov baseline) exists with score_mkv\n",
    "try:\n",
    "    _ = mkv_df.shape\n",
    "except NameError:\n",
    "    mkv_df = lgb_df.copy()\n",
    "    if 'markov_prior' not in mkv_df.columns or mkv_df['markov_prior'].isna().all():\n",
    "        raw_hold = load_rank_df(HOLDOUT_RANK)\n",
    "        key_left = 'candidate_text' if 'candidate_text' in mkv_df.columns else 'candidate'\n",
    "        mkv_df = mkv_df.merge(\n",
    "            raw_hold[['anchor_id','candidate','markov_prior']],\n",
    "            left_on=['anchor_id', key_left], right_on=['anchor_id','candidate'],\n",
    "            how='left'\n",
    "        )\n",
    "        if key_left != 'candidate' and 'candidate' in mkv_df.columns:\n",
    "            mkv_df = mkv_df.drop(columns=['candidate'])\n",
    "    mkv_df['score_mkv'] = mkv_df['markov_prior'].fillna(0.0)\n",
    "\n",
    "# Helper: per-anchor Top-1\n",
    "\n",
    "def per_anchor_top1(df, score_col):\n",
    "    vals = {}\n",
    "    for aid, g in df.groupby('anchor_id'):\n",
    "        g = g.sort_values(score_col, ascending=False)\n",
    "        vals[aid] = int(g['label'].iloc[0] == 1)\n",
    "    return vals\n",
    "\n",
    "lgb_t1 = per_anchor_top1(lgb_df, 'score')\n",
    "mkv_t1 = per_anchor_top1(mkv_df, 'score_mkv')\n",
    "\n",
    "wins = sum(lgb_t1[a] > mkv_t1.get(a, 0) for a in lgb_t1)\n",
    "loss = sum(lgb_t1[a] < mkv_t1.get(a, 0) for a in lgb_t1)\n",
    "\n",
    "d = wins + loss\n",
    "if d == 0:\n",
    "    p_exact = 1.0\n",
    "else:\n",
    "    k = min(wins, loss)\n",
    "    # two-sided exact McNemar via binomial on discordant pairs\n",
    "    from math import comb\n",
    "    p_exact = 2 * sum(comb(d, i) * (0.5 ** d) for i in range(0, k+1))\n",
    "    p_exact = float(min(1.0, p_exact))\n",
    "\n",
    "print(f\"McNemar exact p-value: {p_exact:.4f} | wins: {wins} | loss: {loss} | discordant: {d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "77f6f545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Blend sweep (LightGBM α + (1-α)·Markov) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha_lgb</th>\n",
       "      <th>top1</th>\n",
       "      <th>top2</th>\n",
       "      <th>hit3</th>\n",
       "      <th>mrr3</th>\n",
       "      <th>ndcg3</th>\n",
       "      <th>anchors</th>\n",
       "      <th>ndcg_full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.7586</td>\n",
       "      <td>0.9793</td>\n",
       "      <td>0.9931</td>\n",
       "      <td>0.8736</td>\n",
       "      <td>0.9048</td>\n",
       "      <td>145</td>\n",
       "      <td>0.9077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.7517</td>\n",
       "      <td>0.9793</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8724</td>\n",
       "      <td>0.9057</td>\n",
       "      <td>145</td>\n",
       "      <td>0.9057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.7310</td>\n",
       "      <td>0.9862</td>\n",
       "      <td>0.9931</td>\n",
       "      <td>0.8609</td>\n",
       "      <td>0.8955</td>\n",
       "      <td>145</td>\n",
       "      <td>0.8984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.7310</td>\n",
       "      <td>0.9862</td>\n",
       "      <td>0.9931</td>\n",
       "      <td>0.8609</td>\n",
       "      <td>0.8955</td>\n",
       "      <td>145</td>\n",
       "      <td>0.8984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.7310</td>\n",
       "      <td>0.9793</td>\n",
       "      <td>0.9931</td>\n",
       "      <td>0.8598</td>\n",
       "      <td>0.8946</td>\n",
       "      <td>145</td>\n",
       "      <td>0.8972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.7310</td>\n",
       "      <td>0.9793</td>\n",
       "      <td>0.9931</td>\n",
       "      <td>0.8598</td>\n",
       "      <td>0.8946</td>\n",
       "      <td>145</td>\n",
       "      <td>0.8975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.7310</td>\n",
       "      <td>0.9793</td>\n",
       "      <td>0.9931</td>\n",
       "      <td>0.8598</td>\n",
       "      <td>0.8946</td>\n",
       "      <td>145</td>\n",
       "      <td>0.8975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alpha_lgb    top1    top2    hit3    mrr3   ndcg3  anchors  ndcg_full\n",
       "0       0.85  0.7586  0.9793  0.9931  0.8736  0.9048      145     0.9077\n",
       "1       1.00  0.7517  0.9793  1.0000  0.8724  0.9057      145     0.9057\n",
       "2       0.20  0.7310  0.9862  0.9931  0.8609  0.8955      145     0.8984\n",
       "3       0.30  0.7310  0.9862  0.9931  0.8609  0.8955      145     0.8984\n",
       "4       0.00  0.7310  0.9793  0.9931  0.8598  0.8946      145     0.8972\n",
       "5       0.50  0.7310  0.9793  0.9931  0.8598  0.8946      145     0.8975\n",
       "6       0.70  0.7310  0.9793  0.9931  0.8598  0.8946      145     0.8975"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 0.85\n"
     ]
    }
   ],
   "source": [
    "# Blend LightGBM with Markov prior (alpha tuning)\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "def ensure_markov(df_base):\n",
    "    df = df_base.copy()\n",
    "    if 'markov_prior' in df.columns:\n",
    "        return df\n",
    "    # Try mkv_df first (if created in baselines cell)\n",
    "    try:\n",
    "        src_mkv = mkv_df[['anchor_id','candidate','markov_prior']].copy()\n",
    "        if 'candidate_text' in df.columns and 'candidate_text' in mkv_df.columns:\n",
    "            df = df.merge(src_mkv.rename(columns={'candidate':'candidate_text'}),\n",
    "                          on=['anchor_id','candidate_text'], how='left')\n",
    "        else:\n",
    "            df = df.merge(src_mkv, on=['anchor_id','candidate'], how='left')\n",
    "        return df\n",
    "    except Exception:\n",
    "        pass\n",
    "    # Fallback to raw holdout file\n",
    "    raw_hold = load_rank_df(HOLDOUT_RANK)\n",
    "    key = 'candidate_text' if 'candidate_text' in df.columns else 'candidate'\n",
    "    df = df.merge(raw_hold[['anchor_id','candidate','markov_prior']],\n",
    "                  left_on=['anchor_id', key], right_on=['anchor_id','candidate'],\n",
    "                  how='left', suffixes=('','_raw'))\n",
    "    if 'candidate_raw' in df.columns:\n",
    "        df = df.drop(columns=['candidate_raw'])\n",
    "    return df\n",
    "\n",
    "# start from the LGB-scored holdout built earlier\n",
    "blend_df = ensure_markov(base_df if 'base_df' in globals() else hold_lgb)\n",
    "\n",
    "blend_df = blend_df.loc[:, ~blend_df.columns.duplicated()]\n",
    "\n",
    "\n",
    "alphas = [0.0, 0.2, 0.3, 0.5, 0.7, 0.85, 1.0]\n",
    "rows = []\n",
    "for a in alphas:\n",
    "    tmp = blend_df.copy()\n",
    "    tmp['score_blend'] = a*tmp['score'] + (1-a)*tmp['markov_prior'].fillna(0.0)\n",
    "    met = group_metrics(tmp,  score_col= 'score_blend')\n",
    "    met['ndcg_full'] = ndcg_full(tmp, score_col='score_blend')\n",
    "    rows.append({'alpha_lgb': a, **met})\n",
    "\n",
    "blend_table = pd.DataFrame(rows).sort_values(['top1','ndcg3'], ascending=[False,False]).reset_index(drop=True).round(4)\n",
    "print(\"=== Blend sweep (LightGBM α + (1-α)·Markov) ===\")\n",
    "display(blend_table)\n",
    "\n",
    "best_alpha = float(blend_table.iloc[0]['alpha_lgb'])\n",
    "print(\"Best alpha:\", best_alpha)\n",
    "blend_best = blend_df.copy()\n",
    "blend_best['score'] = best_alpha*blend_best['score'] + (1-best_alpha)*blend_best['markov_prior'].fillna(0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b831f139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Top-1 bootstrap 95% CI: 0.752 [0.697, 0.802]\n",
      "Blended Top-1 bootstrap 95% CI: 0.758 [0.708, 0.812]\n",
      "=== Top 25 features by gain ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>gain</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>markov_prior</td>\n",
       "      <td>185692.484678</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cand_cnt_90d</td>\n",
       "      <td>6013.999537</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cnt_90d</td>\n",
       "      <td>3041.487390</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>last_service</td>\n",
       "      <td>2060.696892</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cand_has_hist</td>\n",
       "      <td>1183.922974</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cnt_r_7_90</td>\n",
       "      <td>807.823212</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>current</td>\n",
       "      <td>738.314798</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cand_cnt_r_7_90</td>\n",
       "      <td>715.094715</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cand_cnt_30d</td>\n",
       "      <td>445.989912</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cnt_30d</td>\n",
       "      <td>411.881701</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cand_recency_days</td>\n",
       "      <td>383.048302</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>recency_days</td>\n",
       "      <td>149.035540</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hour</td>\n",
       "      <td>100.089461</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cnt_r_30_90</td>\n",
       "      <td>73.998299</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>candidate</td>\n",
       "      <td>29.753100</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cnt_7d</td>\n",
       "      <td>23.829399</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cand_cnt_7d</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>dow</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cand_cnt_r_30_90</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              feature           gain  split\n",
       "17       markov_prior  185692.484678     36\n",
       "2        cand_cnt_90d    6013.999537     44\n",
       "10            cnt_90d    3041.487390     49\n",
       "16       last_service    2060.696892     20\n",
       "5       cand_has_hist    1183.922974      2\n",
       "12         cnt_r_7_90     807.823212     19\n",
       "13            current     738.314798     12\n",
       "4     cand_cnt_r_7_90     715.094715      8\n",
       "0        cand_cnt_30d     445.989912     10\n",
       "8             cnt_30d     411.881701      9\n",
       "6   cand_recency_days     383.048302     12\n",
       "18       recency_days     149.035540      7\n",
       "15               hour     100.089461      6\n",
       "11        cnt_r_30_90      73.998299      3\n",
       "7           candidate      29.753100      2\n",
       "9              cnt_7d      23.829399      1\n",
       "1         cand_cnt_7d       0.000000      0\n",
       "14                dow       0.000000      0\n",
       "3    cand_cnt_r_30_90       0.000000      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Bootstrap confidence intervals for Top-1 (LightGBM & best-blend)\n",
    "\n",
    "def bootstrap_metric(df, score_col='score', B=1000, seed=0, fn='top1'):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    anchors = df['anchor_id'].unique()\n",
    "    vals = []\n",
    "    for _ in range(B):\n",
    "        sample = rng.choice(anchors, size=len(anchors), replace=True)\n",
    "        sdf = df[df['anchor_id'].isin(sample)]\n",
    "        m = group_metrics(sdf.rename(columns={score_col:'score'}), 'score')\n",
    "        vals.append(m[fn])\n",
    "    arr = np.array(vals, float)\n",
    "    return float(np.mean(arr)), float(np.percentile(arr, 2.5)), float(np.percentile(arr, 97.5))\n",
    "\n",
    "mean_t1, lo, hi = bootstrap_metric(hold_lgb, 'score', B=1000, seed=42, fn='top1')\n",
    "print(f'LightGBM Top-1 bootstrap 95% CI: {mean_t1:.3f} [{lo:.3f}, {hi:.3f}]')\n",
    "\n",
    "try:\n",
    "    mean_t1_b, lo_b, hi_b = bootstrap_metric(blend_best, 'score', B=1000, seed=43, fn='top1')\n",
    "    print(f'Blended Top-1 bootstrap 95% CI: {mean_t1_b:.3f} [{lo_b:.3f}, {hi_b:.3f}]')\n",
    "except Exception as e:\n",
    "    print('[Blend CI skipped]', e)\n",
    "    \n",
    "# Feature importance (gain/split)\n",
    "try:\n",
    "    feat_names = model_lgb.feature_name()\n",
    "except Exception:\n",
    "    feat_names = None\n",
    "if (not feat_names) or any(str(f).startswith(\"Column_\") for f in feat_names):\n",
    "    feat_names = (cat_cols + ctx_cols + num_cols)\n",
    "\n",
    "fi_df = pd.DataFrame({\n",
    "    \"feature\": feat_names,\n",
    "    \"gain\": model_lgb.feature_importance(importance_type=\"gain\"),\n",
    "    \"split\": model_lgb.feature_importance(importance_type=\"split\"),\n",
    "})\n",
    "fi_df = fi_df.groupby(\"feature\", as_index=False).max().sort_values(\"gain\", ascending=False)\n",
    "print(\"=== Top 25 features by gain ===\")\n",
    "display(fi_df.head(25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "db7e5860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalid-ndcg@3:0.92003\n",
      "[50]\tvalid-ndcg@3:0.90566\n",
      "XGBoost: {'top1': 0.8, 'top2': 0.97931, 'hit3': 0.993103, 'mrr3': 0.894253, 'ndcg3': 0.90603, 'anchors': 145, 'ndcg_full': 0.90823}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import xgboost as xgb\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dtest  = xgb.DMatrix(X_test,  label=y_test)\n",
    "\n",
    "    # XGBoost needs group sizes\n",
    "    dtrain.set_group(groups_train)\n",
    "    dtest.set_group(groups_test)\n",
    "\n",
    "    params_xgb = dict(\n",
    "        objective=\"rank:pairwise\",\n",
    "        eval_metric=\"ndcg@3\",\n",
    "        eta=0.05,\n",
    "        max_depth=8,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.9,\n",
    "        min_child_weight=30,\n",
    "    )\n",
    "\n",
    "    model_xgb = xgb.train(\n",
    "        params_xgb, dtrain,\n",
    "        num_boost_round=800,\n",
    "        evals=[(dtest, \"valid\")],\n",
    "        early_stopping_rounds=50,\n",
    "        verbose_eval=50,\n",
    "    )\n",
    "\n",
    "    hold_xgb = test_enc.copy()\n",
    "    for c in list(hold_xgb.columns[hold_xgb.columns == \"score_xgb\"]):\n",
    "        hold_xgb = hold_xgb.drop(columns=c)\n",
    "    hold_xgb[\"score_xgb\"] = model_xgb.predict(dtest, iteration_range=(0, model_xgb.best_iteration + 1))\n",
    "    # Reuse metrics by renaming score column\n",
    "    met_xgb = group_metrics(hold_xgb.rename(columns={\"score_xgb\": \"score\"}), \"score\")\n",
    "    met_xgb[\"ndcg_full\"] = ndcg_full(hold_xgb.rename(columns={\"score_xgb\": \"score\"}), \"score\")\n",
    "    print(\"XGBoost:\", {k: round(v, 6) if isinstance(v, float) else v for k, v in met_xgb.items()})\n",
    "except Exception as e:\n",
    "    print(\"[XGBoost skipped]\", e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
